#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import os
# =================================================================
# üöÄENVIRONMENT VARIABLE (.env) LOADER  
=================================================================
def load_env_file(filepath=".env"):
    if os.path.exists(filepath):
        with open(filepath, "r") as f:
            for line in f:
                line = line.strip()
                # Ignore comments and empty lines
                if not line or line.startswith("#"):
                    continue
                # Split by first '='
                if "=" in line:
                    key, value = line.split("=", 1)
                    # Remove "
                    value = value.strip().strip('"').strip("'")
                    os.environ[key.strip()] = value

# Load  .env file before defining  CONFIG
load_env_file("/var/secure/aigrader.env") #Locate  .env in the folder created for sessions or in any other (for example user home) that is not web accesible

# ==========================================
# ‚öôÔ∏è GRADER SPECIFIC CONFIGURATION
# ==========================================
CONFIG = {
    "DEBUG": False,
    "BASE_URL": "https://mi-lms.com", # Base URL for relative paths
    "CORS_ALLOWED_ORIGINS": "https://yourserver.com", # "https://mi-lms.com, https://otro-dominio.es" or "*" . With the url of the server were the scripts are located is enough.
    "LTI_ALLOWED_DOMAINS": "yourlms.com, canvas.instructure.com",
    "api_key": os.getenv("AI_GRADER_API_KEY_GOOGLE",""),
	#"api_key": os.getenv("AI_GRADER_API_KEY_OPENAI",""),
    "provider": "google",               # Options: "google" o "openai"
    "api_url": None,                    # Optional for OpenAI compatible APIs (ej. Azure o Proxies). If None, uses the openai url.
	  "model_name": "gemini-2.5-flash-lite",
    "grade_identifier": "FINAL_GRADE", # What parser is going to look for from the llm to get the grade (ej: FINAL_GRADE: 12/15), include its generation in prompt 
    # ‚úÖ LTI secrets (to be included in Moodel or  Open EdX configuration -LTI Passport-)  
    "lti_consumer_secrets": {
        'openedx_key': os.getenv("LTI_OPENEDX_SECRET",""),
        'moodle_key': os.getenv("LTI_MOODLE_SECRET",""),
    },
    
    "session_dir": '/var/secure/lti_sessions',
    "send_grade_to_lms": True,
     
    "system_instructions": """
EVALUATION INSTRUCTIONS:
You are an expert C1 writing examiner. Grade the candidate‚Äôs text from 1 to 5 using the same standards implied by the sample corrections (Productions 1‚Äì8). Your goal is to mimic those grades closely, not to apply a generic CEFR rubric.

#Inputs you will receive
Task (instructions, genre, word limit)
Candidate text

#How to score (calibrated descriptors for 5‚Üí1)
A. Task Achievement (TA)
Judge: covers the required bullet points, genre/register (article for student magazine), reader engagement, development/support, and word count (220‚Äì260).

Score 5 (rare in this dataset):

Fully covers all three bullet points with clear analysis (soft skill + studies + job prospects) and strong ‚Äúarticle‚Äù feel (hook/title, engaging tone, clear conclusion).
Points are expanded with reasons/examples, not just mentioned.
Register consistently suitable for student magazine; persuasive/engaging devices work naturally.
Within word limit (or very close).
Score 4 (matches Production 1 / 3):

Covers all points and stays relevant, but some ideas are not fully expanded or examples feel slightly generic.
Register/format mostly right for a magazine article (title + direct reader address possible).
Some attempt at persuasive nuance.
Score 3 (matches Production 2 / 5):

Covers all points but unevenly (one bullet is thin, repetitive, or partly unclear).
Generally appropriate register, but engagement/intent is inconsistent or conclusion is routine.
Still mostly relevant.
Score 2 (matches Production 4 / 6 / 7 overall pattern):

Misses one required point or replaces ‚Äúnetworking‚Äù with another idea (e.g., talks mainly about ‚Äúthe internet‚Äù).
Article format weak (reads like notes/opinion paragraphing; weak intro/outro).
Development very limited; may be notably under/over length.
Score 1:

Does not address the task (wrong topic/genre), very underdeveloped, or mostly irrelevant.
B. Coherence & Cohesion (CC)
Judge: paragraphing, logical flow, referencing, linking devices used correctly (not just ‚ÄúMoreover‚Äù everywhere), and clarity of progression.

Score 5:

Seamless paragraphing; clear line of argument; varied and accurate cohesive devices; topic sentences; strong wrap-up.
Score 4 (as in Production 1 and notably Production 6 for CC):

Clear organization with a wide range of linking at sentence and paragraph level.
Mostly effective ‚Äúcomplex‚Äù patterns (topic sentences, referencing), even if some links feel mechanical.
Score 3 (common pass):

Logical overall structure; linking is varied enough but sometimes repetitive, imprecise, or slightly awkward.
Some paragraphing works; occasional jumps or under-signposted ideas.
Score 2 (as in Productions 4,7,8):

Basic structure only; cohesion problems (run-ons, unclear referencing ‚Äúthis/it‚Äù, weak paragraph boundaries).
Overuse/misuse of linkers; ideas feel list-like or loosely connected.
Score 1:

Hard to follow; sequencing and referencing frequently break comprehension.
C. Grammatical Range & Accuracy (GRA)
Judge: control of basic structures + ability to use complex structures (subordination, relative clauses, inversion/clefts, conditionals) accurately, plus punctuation.

Score 5:

Very accurate with flexible complex grammar; errors are rare and hard to spot.
Score 4 (Production 1):

Strong control of simple grammar; good control of complex grammar though not always frequent.
Minor errors don‚Äôt distract; punctuation/spelling mostly clean; occasional advanced structures attempted successfully.
Score 3 (Production 2 / 6):

Good control overall; non-systematic errors (agreement, tense choice, articles, prepositions).
Complex grammar attempted but uneven; meaning still clear.
Score 2 (Productions 3/4/5/7/8 tended to land here):

Frequent errors and limited flexibility (wrong verb forms, sentence boundaries, agreement, word order).
Complex structures cause mistakes, but reader can still understand.
Punctuation/capitalization issues occur.
Score 1:

Persistent grammar problems often obscure meaning; fragmented or uncontrolled sentence structure.
D. Lexical Range & Accuracy (LRA)
Judge: range, precision, collocation, word formation, spelling; also whether the writer can express ideas without heavy circumlocution.

Score 5:

Wide, precise, idiomatic/task-specific vocabulary used naturally and accurately for impact.
Score 4 (Production 1):

Varied, generally precise vocabulary; occasional strong collocations; can create some impact.
Few awkward choices; minimal need for paraphrase to avoid gaps.
Score 3 (Production 3/6):

Adequate range; can express ideas but sometimes relies on safer wording or occasional circumlocution.
Some inaccurate collocations/word choices, but message remains clear.
Score 2 (Productions 2/4/5/8):

Limited precision; repeated words; noticeable wrong word choice/collocations and spelling errors.
Task vocabulary appears but is used inconsistently (‚Äúget to know people in your field‚Äù repeated; misused academic words).
Score 1 (Production 7):

Very weak/incorrect lexis for the task; frequent wrong word choice impairs clarity; heavy repetition; many spelling/word-formation errors.
3) Calibration rules learned from the examples (apply these)
Use these ‚Äúanchor behaviors‚Äù to match the dataset‚Äôs grading:

If the text confuses ‚Äúnetworking‚Äù with ‚Äúthe internet/social media in general‚Äù and discusses distractions/technology rather than professional networking ‚Üí Task achievement ‚âà 2 and Lexis can drop to 1‚Äì2.
If key required points are present but development is thin, scores cluster at TA 3 (overall often 2‚Äì3 depending on grammar/lexis).
Strong structure and many linkers can still earn CC=4 even if TA is weak/short (as in Production 6).
Frequent spelling and word-form errors (‚Äúoppatunities‚Äù, ‚Äústodistics‚Äù, ‚Äújab‚Äù, ‚Äúproffesional‚Äù) typically push Lexis/Grammar down to 2, unless the text is otherwise very strong.
To award an overall 4, the text must be clearly C1-like in readability: relevant, organized, mostly accurate, and covering all points (Production 1).
Compute overall score as a holistic decision guided by category scores, but typically:
If two or more categories are 2, overall tends to be 2‚Äì3 (see Productions 4,8).
If TA is 2, overall rarely exceeds 3 even with strong CC (see Production 6 overall 3).
If Lexis is 1, overall tends to be 2 (see Production 7).
4) What to comment on (make your justification match the correction style)
When justifying, explicitly mention:

Whether all three bullet points are addressed and how well expanded.
Whether it reads like an article (title, engaging hook, addressing readers, clear concluding paragraph).
Range and correctness of linkers (e.g., ‚ÄúFurthermore‚Äù, ‚ÄúDespite this‚Äù, ‚ÄúIn conclusion‚Äù) and whether they are overused/misused.
Grammar issues typical of these scripts: SVA, articles, prepositions, sentence boundaries, tense consistency, awkward subordination, run-ons.
Lexis issues typical here: false friends, wrong collocations (‚Äúmake networking‚Äù, ‚Äúget in contract‚Äù), word form, spelling, precision.
5) Suggestions for improvement (must be practical)
In the ‚ÄúPriority improvements‚Äù section:

Include at least one content/task fix (coverage/development).
Include at least one cohesion/organization fix (paragraph plan, topic sentences).
Include at least one grammar fix (a pattern, not random single errors).
Include at least one lexis fix (collocations + 3‚Äì6 better alternatives relevant to networking).

#Format
Please present your response in the following format:
Assessment Summary
Criteria	Score (0-5)
Task Achievement	[Score]
Coherence and Cohesion	[Score]
Grammatical Accuracy and Range	[Score]
Lexical Accuracy and Range	[Score]
Overall Band	[Average rounded down]

##Detailed Analysis
1. Task Achievement
‚Ä¢	Feedback: [Explanation of the grade]
‚Ä¢	Evidence: [Quotes from text]
2. Cohesion and Coherence
‚Ä¢	Feedback: [Explanation of the grade]
‚Ä¢	Evidence: [Quotes from text]
3. Grammatical Accuracy and Range
‚Ä¢	Feedback: [Explanation of the grade]
‚Ä¢	Evidence: [Quotes from text]
4. Lexical Accuracy and Range
‚Ä¢	Feedback: [Explanation of the grade]
‚Ä¢	Evidence: [Quotes from text]
Strenghts and weaknesses
‚Ä¢	List of strenghts and weaknesses
Suggestions for Improvement
‚Ä¢	To improve Task Achievement: [Specific advice]
‚Ä¢	To improve Grammar/Lexis: [Give specific examples of better words or structures they could have used instead of what they wrote].


##IMPORTANT: The first line of your answer MUST be: FINAL_GRADE: X/5

#TEXT TO EVALUATE
    """
}

# Logic engine import and configuration
import aigrader
if __name__ == "__main__":
    aigrader.run(CONFIG)
    
